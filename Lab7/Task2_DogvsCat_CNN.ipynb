{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab7_Exercise2_DogvsCat_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagar610/CE888/blob/main/Lab7/Task2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTh9DiKVslsJ"
      },
      "source": [
        "## Dogs vs. Cats \n",
        "\n",
        "In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n",
        "\n",
        "Ref: https://medium.com/@thegrigorian/rolling-in-the-deep-cnn-c8d3f7108c8c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSBI-_mSSY1g"
      },
      "source": [
        "Get your API Key from Kaggle using following steps:\n",
        "1. Login to [Kaggle](https://www.kaggle.com/) or Register if you don't have account\n",
        "2. Open Dataset (https://www.kaggle.com/c/dogs-vs-cats/rules) and accept terms and condition. \n",
        "3. On the top right corner click on your Icon and go to accounts and press a button \"Create New API Token\". It will download a JSON file containing your username and key. \n",
        "4. Now, paste both below. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXSOc0tZIGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfd40ac-023f-466a-ed52-6661507d8707"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"priyankabhagwat\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"58904535b6a18ff808eeb4af686142fa\" # key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle (https://www.kaggle.com/c/dogs-vs-cats/data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.zip to /content\n",
            " 96% 521M/543M [00:03<00:00, 130MB/s]\n",
            "100% 543M/543M [00:03<00:00, 157MB/s]\n",
            "Downloading test1.zip to /content\n",
            " 98% 267M/271M [00:02<00:00, 124MB/s]\n",
            "100% 271M/271M [00:03<00:00, 94.2MB/s]\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 77.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwIL8d1n7eS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8429250-1ebe-4d1d-b9da-f6abf507faf5"
      },
      "source": [
        "# Unzip training data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/train.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa2Bj5i7pPKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503a5bac-d2f4-4b21-f4ef-a1457b6bfaa3"
      },
      "source": [
        "# Get all the paths\n",
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ERlHkfHqpK8"
      },
      "source": [
        "# Make new base directory\n",
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "os.mkdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANB1UJ6rQhM"
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULRgL9s9rV8T"
      },
      "source": [
        "import shutil\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3XAbIyr7vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48781e3a-fcae-4713-e2d2-3ddb4dcd7a83"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yTA21_r-ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4874bea-6db9-4eab-dacd-e56072eae659"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mG8wekxsBVS"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zS4Klm8qWp6"
      },
      "source": [
        "## Using ImageDataGenerator to read images from directories\n",
        "As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RGB grids of pixels.\n",
        "* Convert these into floating-point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ7XU7t9sEh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008e578e-2c16-419e-b46f-3330c5deac68"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgLywySqm4u"
      },
      "source": [
        "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the generator—that is, after having run for `steps_per_epoch` gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
        "\n",
        "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMyfPphJsJG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea26d58-8890-436e-efc0-41a921001a69"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 41s 75ms/step - loss: 0.6980 - acc: 0.5071 - val_loss: 0.6847 - val_acc: 0.5600\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6686 - acc: 0.6057 - val_loss: 0.6492 - val_acc: 0.6000\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6327 - acc: 0.6632 - val_loss: 0.6371 - val_acc: 0.6300\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6034 - acc: 0.6836 - val_loss: 0.6120 - val_acc: 0.6400\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.5644 - acc: 0.7161 - val_loss: 0.6344 - val_acc: 0.6500\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.5220 - acc: 0.7603 - val_loss: 0.5396 - val_acc: 0.7250\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.4914 - acc: 0.7601 - val_loss: 0.5550 - val_acc: 0.7200\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4676 - acc: 0.7832 - val_loss: 0.5421 - val_acc: 0.7450\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4238 - acc: 0.8025 - val_loss: 0.5977 - val_acc: 0.6900\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.4093 - acc: 0.8039 - val_loss: 0.5098 - val_acc: 0.7500\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.3885 - acc: 0.8306 - val_loss: 0.5692 - val_acc: 0.7000\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.3462 - acc: 0.8496 - val_loss: 0.5359 - val_acc: 0.7750\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.3156 - acc: 0.8685 - val_loss: 0.7360 - val_acc: 0.6800\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.3144 - acc: 0.8649 - val_loss: 0.4679 - val_acc: 0.7850\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.2792 - acc: 0.8876 - val_loss: 0.6106 - val_acc: 0.7350\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.2565 - acc: 0.9016 - val_loss: 0.5130 - val_acc: 0.8000\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.2403 - acc: 0.9123 - val_loss: 0.5529 - val_acc: 0.7500\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.2076 - acc: 0.9347 - val_loss: 0.7075 - val_acc: 0.7300\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1900 - acc: 0.9286 - val_loss: 0.7332 - val_acc: 0.7000\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.1828 - acc: 0.9299 - val_loss: 0.6805 - val_acc: 0.7350\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.1494 - acc: 0.9524 - val_loss: 0.5957 - val_acc: 0.7850\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.1330 - acc: 0.9539 - val_loss: 0.6143 - val_acc: 0.7800\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.1096 - acc: 0.9663 - val_loss: 0.8423 - val_acc: 0.7200\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.1017 - acc: 0.9722 - val_loss: 1.0995 - val_acc: 0.6850\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1042 - acc: 0.9643 - val_loss: 0.7181 - val_acc: 0.7400\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.0704 - acc: 0.9781 - val_loss: 0.9489 - val_acc: 0.7350\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.0650 - acc: 0.9808 - val_loss: 1.3247 - val_acc: 0.6850\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.0535 - acc: 0.9817 - val_loss: 1.2148 - val_acc: 0.6900\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.0471 - acc: 0.9913 - val_loss: 1.0145 - val_acc: 0.7450\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.0349 - acc: 0.9940 - val_loss: 0.8840 - val_acc: 0.7400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZaZ2HWZsNUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "034e1369-88cc-486d-b3f9-f02be96f8602"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZmXmBcq_8-"
      },
      "source": [
        "## Convolutional Networks with Dropout\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/ee6fa1073247cd2c3d241300caf110d7a7541bc5/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4972644a355067684439596f4f7956415137334d4a772e676966)\n",
        "\n",
        "Ref: https://github.com/mneha4/Training-Neural-Nets---Guidelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu3cqeYQrDeN"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSeLpvY0rH7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7197e71d-1594-4e38-9ae8-965724966073"
      },
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ETG4ISOaU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd9fa7c-da35-4825-822e-d5af12dc37d5"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 20s 190ms/step - loss: 0.7001 - acc: 0.5172 - val_loss: 0.6867 - val_acc: 0.5480\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.6891 - acc: 0.5455 - val_loss: 0.6690 - val_acc: 0.5740\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.6810 - acc: 0.5579 - val_loss: 0.6713 - val_acc: 0.5860\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.6683 - acc: 0.5821 - val_loss: 0.6739 - val_acc: 0.5800\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.6686 - acc: 0.5904 - val_loss: 0.6507 - val_acc: 0.6090\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.6595 - acc: 0.6000 - val_loss: 0.6543 - val_acc: 0.6190\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.6486 - acc: 0.6171 - val_loss: 0.6438 - val_acc: 0.6270\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.6329 - acc: 0.6288 - val_loss: 0.5855 - val_acc: 0.6820\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.6088 - acc: 0.6699 - val_loss: 0.5979 - val_acc: 0.6580\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.6019 - acc: 0.6770 - val_loss: 0.5697 - val_acc: 0.7010\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.5911 - acc: 0.6614 - val_loss: 0.5656 - val_acc: 0.7020\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.6044 - acc: 0.6569 - val_loss: 0.5658 - val_acc: 0.7110\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.5749 - acc: 0.6982 - val_loss: 0.5728 - val_acc: 0.6990\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.5760 - acc: 0.6936 - val_loss: 0.6533 - val_acc: 0.6290\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.5700 - acc: 0.6992 - val_loss: 0.5583 - val_acc: 0.6940\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.5554 - acc: 0.7179 - val_loss: 0.5518 - val_acc: 0.6960\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.5854 - acc: 0.7036 - val_loss: 0.6423 - val_acc: 0.6560\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.5674 - acc: 0.6906 - val_loss: 0.7379 - val_acc: 0.6420\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.5527 - acc: 0.7023 - val_loss: 0.6145 - val_acc: 0.6700\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.5640 - acc: 0.7083 - val_loss: 0.5340 - val_acc: 0.7310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdU5yrkUF_b"
      },
      "source": [
        "# Task 2:\n",
        "\n",
        "We have used Dropout to enhance the performance of the CNN model. Can you please use whatever you like to further enhance the performance from `val_acc: 0.7506`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDM6MBeOP8v",
        "outputId": "d5016dab-daeb-4d9a-aee2-399249a0ba8d"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=1500//32,\n",
        "                              epochs=64,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=1500//32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.5406 - acc: 0.7198WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 46 batches). You may need to use the repeat() function when building your dataset.\n",
            "46/46 [==============================] - 15s 322ms/step - loss: 0.5406 - acc: 0.7198 - val_loss: 0.5510 - val_acc: 0.7130\n",
            "Epoch 2/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.5597 - acc: 0.7040\n",
            "Epoch 3/64\n",
            "46/46 [==============================] - 12s 252ms/step - loss: 0.5317 - acc: 0.7404\n",
            "Epoch 4/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.5502 - acc: 0.7260\n",
            "Epoch 5/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.5492 - acc: 0.7109\n",
            "Epoch 6/64\n",
            "46/46 [==============================] - 12s 253ms/step - loss: 0.5314 - acc: 0.7218\n",
            "Epoch 7/64\n",
            "46/46 [==============================] - 12s 253ms/step - loss: 0.5325 - acc: 0.7431\n",
            "Epoch 8/64\n",
            "46/46 [==============================] - 12s 253ms/step - loss: 0.5471 - acc: 0.7260\n",
            "Epoch 9/64\n",
            "46/46 [==============================] - 12s 252ms/step - loss: 0.5102 - acc: 0.7569\n",
            "Epoch 10/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.5271 - acc: 0.7266\n",
            "Epoch 11/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.5222 - acc: 0.7493\n",
            "Epoch 12/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.5209 - acc: 0.7246\n",
            "Epoch 13/64\n",
            "46/46 [==============================] - 11s 250ms/step - loss: 0.5161 - acc: 0.7424\n",
            "Epoch 14/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.5209 - acc: 0.7349\n",
            "Epoch 15/64\n",
            "46/46 [==============================] - 12s 250ms/step - loss: 0.5187 - acc: 0.7588\n",
            "Epoch 16/64\n",
            "46/46 [==============================] - 11s 247ms/step - loss: 0.5048 - acc: 0.7596\n",
            "Epoch 17/64\n",
            "46/46 [==============================] - 12s 250ms/step - loss: 0.5294 - acc: 0.7273\n",
            "Epoch 18/64\n",
            "46/46 [==============================] - 12s 250ms/step - loss: 0.5156 - acc: 0.7376\n",
            "Epoch 19/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4985 - acc: 0.7555\n",
            "Epoch 20/64\n",
            "46/46 [==============================] - 12s 254ms/step - loss: 0.5100 - acc: 0.7405\n",
            "Epoch 21/64\n",
            "46/46 [==============================] - 12s 252ms/step - loss: 0.5153 - acc: 0.7466\n",
            "Epoch 22/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.4926 - acc: 0.7562\n",
            "Epoch 23/64\n",
            "46/46 [==============================] - 12s 254ms/step - loss: 0.5204 - acc: 0.7269\n",
            "Epoch 24/64\n",
            "46/46 [==============================] - 12s 254ms/step - loss: 0.4902 - acc: 0.7649\n",
            "Epoch 25/64\n",
            "46/46 [==============================] - 12s 250ms/step - loss: 0.5046 - acc: 0.7445\n",
            "Epoch 26/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4942 - acc: 0.7569\n",
            "Epoch 27/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.5087 - acc: 0.7500\n",
            "Epoch 28/64\n",
            "46/46 [==============================] - 12s 253ms/step - loss: 0.4958 - acc: 0.7445\n",
            "Epoch 29/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4995 - acc: 0.7603\n",
            "Epoch 30/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4916 - acc: 0.7596\n",
            "Epoch 31/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4884 - acc: 0.7644\n",
            "Epoch 32/64\n",
            "46/46 [==============================] - 12s 250ms/step - loss: 0.4883 - acc: 0.7582\n",
            "Epoch 33/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4764 - acc: 0.7692\n",
            "Epoch 34/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4817 - acc: 0.7617\n",
            "Epoch 35/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4897 - acc: 0.7610\n",
            "Epoch 36/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4830 - acc: 0.7685\n",
            "Epoch 37/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4685 - acc: 0.7672\n",
            "Epoch 38/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4892 - acc: 0.7527\n",
            "Epoch 39/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4823 - acc: 0.7644\n",
            "Epoch 40/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4648 - acc: 0.7720\n",
            "Epoch 41/64\n",
            "46/46 [==============================] - 11s 246ms/step - loss: 0.4645 - acc: 0.7768\n",
            "Epoch 42/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.4831 - acc: 0.7656\n",
            "Epoch 43/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4739 - acc: 0.7610\n",
            "Epoch 44/64\n",
            "46/46 [==============================] - 12s 251ms/step - loss: 0.4660 - acc: 0.7761\n",
            "Epoch 45/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4735 - acc: 0.7761\n",
            "Epoch 46/64\n",
            "46/46 [==============================] - 12s 252ms/step - loss: 0.4589 - acc: 0.7812\n",
            "Epoch 47/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4519 - acc: 0.7933\n",
            "Epoch 48/64\n",
            "46/46 [==============================] - 11s 247ms/step - loss: 0.4557 - acc: 0.7816\n",
            "Epoch 49/64\n",
            "46/46 [==============================] - 11s 246ms/step - loss: 0.4644 - acc: 0.7761\n",
            "Epoch 50/64\n",
            "46/46 [==============================] - 11s 245ms/step - loss: 0.4539 - acc: 0.7898\n",
            "Epoch 51/64\n",
            "46/46 [==============================] - 11s 246ms/step - loss: 0.4526 - acc: 0.7823\n",
            "Epoch 52/64\n",
            "46/46 [==============================] - 11s 247ms/step - loss: 0.4565 - acc: 0.7826\n",
            "Epoch 53/64\n",
            "46/46 [==============================] - 11s 245ms/step - loss: 0.4609 - acc: 0.7823\n",
            "Epoch 54/64\n",
            "46/46 [==============================] - 11s 245ms/step - loss: 0.4480 - acc: 0.7953\n",
            "Epoch 55/64\n",
            "46/46 [==============================] - 11s 244ms/step - loss: 0.4537 - acc: 0.7816\n",
            "Epoch 56/64\n",
            "46/46 [==============================] - 11s 246ms/step - loss: 0.4518 - acc: 0.7857\n",
            "Epoch 57/64\n",
            "46/46 [==============================] - 11s 243ms/step - loss: 0.4589 - acc: 0.7823\n",
            "Epoch 58/64\n",
            "46/46 [==============================] - 11s 249ms/step - loss: 0.4564 - acc: 0.7928\n",
            "Epoch 59/64\n",
            "46/46 [==============================] - 11s 248ms/step - loss: 0.4571 - acc: 0.7795\n",
            "Epoch 60/64\n",
            "46/46 [==============================] - 11s 243ms/step - loss: 0.4375 - acc: 0.7864\n",
            "Epoch 61/64\n",
            "46/46 [==============================] - 11s 247ms/step - loss: 0.4512 - acc: 0.7830\n",
            "Epoch 62/64\n",
            "46/46 [==============================] - 11s 244ms/step - loss: 0.4474 - acc: 0.7878\n",
            "Epoch 63/64\n",
            "46/46 [==============================] - 11s 246ms/step - loss: 0.4521 - acc: 0.7926\n",
            "Epoch 64/64\n",
            "46/46 [==============================] - 11s 245ms/step - loss: 0.4507 - acc: 0.7857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fca97e5bad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WeNZwhmOnIg"
      },
      "source": [
        "We got 80% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi9w7ExXc05i"
      },
      "source": [
        "**Transfer Leanrning method**\n",
        "\n",
        "Code source: https://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGRdBNlJQHGC",
        "outputId": "b584bb04-0698-4e64-d766-41d663b92266"
      },
      "source": [
        "from keras.applications import InceptionResNetV2\n",
        "\n",
        "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87W2Dt_pc0Ly"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEMiKnPMPISf",
        "outputId": "539f0b7e-9b39-4353-c8dd-83e46bc3d524"
      },
      "source": [
        "print('Number of trainable weights before freezing the conv base:', len(model.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print('Number of trainable weights after freezing the conv base:', len(model.trainable_weights))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable weights before freezing the conv base: 492\n",
            "Number of trainable weights after freezing the conv base: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHRgQOovPMe6"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUSW-6mmhhyR",
        "outputId": "f8788228-683e-4cd4-c44d-43afdb14e2e1"
      },
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=1500//32,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=1500//32)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.7481 - acc: 0.7833WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 46 batches). You may need to use the repeat() function when building your dataset.\n",
            "46/46 [==============================] - 30s 434ms/step - loss: 0.7403 - acc: 0.7850 - val_loss: 0.0974 - val_acc: 0.9600\n",
            "Epoch 2/20\n",
            "46/46 [==============================] - 12s 269ms/step - loss: 0.2002 - acc: 0.9212\n",
            "Epoch 3/20\n",
            "46/46 [==============================] - 13s 281ms/step - loss: 0.1983 - acc: 0.9210\n",
            "Epoch 4/20\n",
            "46/46 [==============================] - 12s 269ms/step - loss: 0.1844 - acc: 0.9258\n",
            "Epoch 5/20\n",
            "46/46 [==============================] - 13s 272ms/step - loss: 0.1629 - acc: 0.9361\n",
            "Epoch 6/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1998 - acc: 0.9287\n",
            "Epoch 7/20\n",
            "46/46 [==============================] - 12s 264ms/step - loss: 0.1289 - acc: 0.9511\n",
            "Epoch 8/20\n",
            "46/46 [==============================] - 13s 271ms/step - loss: 0.1214 - acc: 0.9470\n",
            "Epoch 9/20\n",
            "46/46 [==============================] - 12s 270ms/step - loss: 0.1600 - acc: 0.9422\n",
            "Epoch 10/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1384 - acc: 0.9441\n",
            "Epoch 11/20\n",
            "46/46 [==============================] - 12s 269ms/step - loss: 0.1191 - acc: 0.9512\n",
            "Epoch 12/20\n",
            "46/46 [==============================] - 12s 268ms/step - loss: 0.1140 - acc: 0.9544\n",
            "Epoch 13/20\n",
            "46/46 [==============================] - 12s 269ms/step - loss: 0.1385 - acc: 0.9378\n",
            "Epoch 14/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1266 - acc: 0.9454\n",
            "Epoch 15/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1017 - acc: 0.9546\n",
            "Epoch 16/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1328 - acc: 0.9527\n",
            "Epoch 17/20\n",
            "46/46 [==============================] - 12s 264ms/step - loss: 0.1090 - acc: 0.9564\n",
            "Epoch 18/20\n",
            "46/46 [==============================] - 12s 269ms/step - loss: 0.1094 - acc: 0.9567\n",
            "Epoch 19/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.1101 - acc: 0.9568\n",
            "Epoch 20/20\n",
            "46/46 [==============================] - 12s 266ms/step - loss: 0.0936 - acc: 0.9725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fca94812590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGtpvYBiRwXz"
      },
      "source": [
        "With transfer leaning the accuracy is raised to 95%"
      ]
    }
  ]
}